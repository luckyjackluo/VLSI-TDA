{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91ae8d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gudhi as gd\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from ripser import Rips\n",
    "import pickle\n",
    "import os\n",
    "import persim\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib.pyplot import figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ee7f099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_vis(s_n, opt = \"debug\"):\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(5,10))\n",
    "    sub_g = nx.ego_graph(G, s_n, radius=5)\n",
    "    sub_g.remove_edges_from(list(nx.selfloop_edges(sub_g)))\n",
    "    edgs = list(sub_g.edges)\n",
    "    col = []\n",
    "    row = []\n",
    "    for edg in edgs:\n",
    "        col.append(edg[0])\n",
    "        row.append(edg[1])\n",
    "\n",
    "    p_input = set()\n",
    "    p_output = set()\n",
    "\n",
    "    p_input.add(s_n)\n",
    "\n",
    "    o_d = sub_g.out_degree\n",
    "    i_d = sub_g.in_degree\n",
    "\n",
    "    for node in sub_g:\n",
    "        if o_d[node] == 0 and i_d[node] == 0:\n",
    "            continue\n",
    "\n",
    "        if o_d[node] == 0:\n",
    "            p_output.add(node)\n",
    "\n",
    "        if i_d[node] == 0:\n",
    "            p_input.add(node)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    gen = nx.dfs_edges(sub_g, source=s_n)\n",
    "    delay_dict = {}\n",
    "    delay_dict[s_n] = 0\n",
    "    for edge in list(gen):\n",
    "        n1 = edge[0]\n",
    "        n2 = edge[1]\n",
    "        delay = delay_dict[n1] + 1\n",
    "        if n2 in delay_dict.keys():\n",
    "            if delay > delay_dict[n2]:\n",
    "                delay_dict[n2] = delay\n",
    "                    \n",
    "        else:\n",
    "            delay_dict[n2] = delay\n",
    "    \n",
    "    \n",
    "\n",
    "    d_lst = []\n",
    "    for delay in range(max(delay_dict.values()) + 1):\n",
    "        delay_level_lst = []\n",
    "        for node in delay_dict.keys():\n",
    "            if delay_dict[node] == delay:\n",
    "                delay_level_lst.append(node)\n",
    "\n",
    "        if len(delay_level_lst) == 0:\n",
    "            continue\n",
    "        d_lst.append(delay_level_lst)\n",
    "\n",
    "    to_level = len(d_lst) \n",
    "    mid = np.max([len(lst) for lst in d_lst])/2\n",
    "\n",
    "    pos = {}\n",
    "\n",
    "    for delay in range(len(d_lst)):\n",
    "        lst = d_lst[delay]\n",
    "        for in_pos in range(len(lst)):\n",
    "            node = lst[in_pos]\n",
    "            pos[node] = ((mid - len(lst)) + in_pos*2, (len(d_lst) - delay))\n",
    "\n",
    "    ax = axes[0]\n",
    "    dgms = np.load(f\"dgms/pd_{s_n}.npy\", allow_pickle=True)\n",
    "    ax.scatter([dgms[0][i][1][0] for i in range(len(dgms[0]))], [dgms[0][i][1][1] for i in range(len(dgms[0]))], color=\"blue\")\n",
    "    ax.scatter([dgms[2][i][1][0] for i in range(len(dgms[2]))], [dgms[2][i][1][1] for i in range(len(dgms[2]))], color=\"blue\")\n",
    "    ax.scatter([dgms[1][i][1][0] for i in range(len(dgms[1]))], [dgms[1][i][1][1] for i in range(len(dgms[1]))], color=\"blue\")\n",
    "    ax.scatter([dgms[3][i][1][0] for i in range(len(dgms[3]))], [dgms[3][i][1][1] for i in range(len(dgms[3]))], color=\"orange\")\n",
    "    ax.plot([0, to_level],[0, to_level])\n",
    "    ax = axes[1]\n",
    "\n",
    "    if opt==\"debug\":\n",
    "        color = []\n",
    "        for node in sub_g:\n",
    "            if node in p_input:\n",
    "                color.append(\"red\")\n",
    "            else:\n",
    "                color.append(\"blue\")\n",
    "        print(delay_dict)\n",
    "        nx.draw(sub_g, ax=ax, node_color=color, labels={node:node for node in sub_g})\n",
    "    \n",
    "    if opt==\"show\":\n",
    "        color = []\n",
    "        for node in pos.keys():\n",
    "            if node in p_input:\n",
    "                color.append(\"red\")\n",
    "            else:\n",
    "                color.append(\"blue\")\n",
    "        \n",
    "        print(delay_dict)\n",
    "        nx.draw(sub_g, ax=ax, pos=pos, node_color=color, labels={node:node for node in pos.keys()}, nodelist=pos.keys())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "140d2a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph:\n",
    "    # Constructor\n",
    "    def __init__(self, edges, n):\n",
    " \n",
    "        # A list of lists to represent an adjacency list\n",
    "        self.adjList = [[] for _ in range(n)]\n",
    " \n",
    "        # add edges to the directed graph\n",
    "        for (source, dest, weight) in edges:\n",
    "            self.adjList[source].append((dest, weight))\n",
    " \n",
    " \n",
    "# Perform DFS on the graph and set the departure time of all\n",
    "# vertices of the graph\n",
    "def DFS(graph, v, discovered, departure, time):\n",
    "    # mark the current node as discovered\n",
    "    discovered[v] = True\n",
    " \n",
    "    # set arrival time â€“ not needed\n",
    "    # time = time + 1\n",
    " \n",
    "    # do for every edge (v, u)\n",
    "    for (u, w) in graph.adjList[v]:\n",
    "        # if `u` is not yet discovered\n",
    "        if not discovered[u]:\n",
    "            time = DFS(graph, u, discovered, departure, time)\n",
    " \n",
    "    # ready to backtrack\n",
    "    # set departure time of vertex `v`\n",
    "    departure[time] = v\n",
    "    time = time + 1\n",
    " \n",
    "    return time\n",
    " \n",
    "def findLongestDistance(graph, source, n):\n",
    "    # `departure` stores vertex number having its departure\n",
    "    # time equal to the index of it\n",
    "    departure = [-1] * n\n",
    " \n",
    "    # to keep track of whether a vertex is discovered or not\n",
    "    discovered = [False] * n\n",
    "    time = 0\n",
    " \n",
    "    # perform DFS on all undiscovered vertices\n",
    "    for i in range(n):\n",
    "        if not discovered[i]:\n",
    "            time = DFS(graph, i, discovered, departure, time)\n",
    " \n",
    "    cost = [sys.maxsize] * n\n",
    "    cost[source] = 0\n",
    " \n",
    "    # Process the vertices in topological order, i.e., in order\n",
    "    # of their decreasing departure time in DFS\n",
    "    added = []\n",
    "    \n",
    "    for i in reversed(range(n)):\n",
    "     \n",
    "        # for each vertex in topological order,\n",
    "        # relax the cost of its adjacent vertices\n",
    "        v = departure[i]\n",
    "        # edge from `v` to `u` having weight `w`\n",
    "        for (u, w) in graph.adjList[v]:\n",
    "            w = -w     # make edge weight negative\n",
    "            # if the distance to destination `u` can be shortened by\n",
    "            # taking edge (v, u), then update cost to the new lower value\n",
    "            if cost[v] != sys.maxsize and cost[v] + w < cost[u]:\n",
    "                cost[u] = cost[v] + w\n",
    "                \n",
    "            \n",
    "    \n",
    "    \n",
    "    dist = dict()\n",
    "    for i in range(n):\n",
    "        dist[i] = {-cost[i]}\n",
    "        \n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da730858",
   "metadata": {},
   "outputs": [],
   "source": [
    "netlist_name = \"jpeg_300_off_low_GENUS\"\n",
    "G = nx.read_gpickle(f\"/home/zluo/input/{netlist_name}.gpickle\")\n",
    "\n",
    "p_input = set()\n",
    "p_output = set()\n",
    "o_d = G.out_degree\n",
    "i_d = G.in_degree\n",
    "\n",
    "for node in G:\n",
    "    if o_d[node] == 0 and i_d[node] == 0:\n",
    "        continue\n",
    "\n",
    "    if o_d[node] == 0:\n",
    "        p_output.add(node)\n",
    "\n",
    "    if i_d[node] == 0:\n",
    "        p_input.add(node)\n",
    "\n",
    "\n",
    "all_raw = []\n",
    "\n",
    "for v in p_input:\n",
    "    all_raw.append(nx.shortest_path_length(G, v))    \n",
    "\n",
    "delay_dict = all_raw[0]\n",
    "delay_dict = {key: [delay_dict[key]] for key in delay_dict.keys()}\n",
    "for dist in all_raw[1:]:\n",
    "    for key in dist.keys(): \n",
    "        val = dist[key]\n",
    "        if key in delay_dict.keys():\n",
    "            delay_dict[key] = delay_dict[key] + [val]\n",
    "        else:\n",
    "            delay_dict[key] = [val]\n",
    "\n",
    "delay_dict = {key: min(delay_dict[key]) for key in delay_dict.keys()}\n",
    "\n",
    "with open(f'/home/zluo/output/delay_dict_{netlist_name}_shortest.pkl', 'wb') as f:\n",
    "    pickle.dump(delay_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80bd1d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the data\n",
    "\n",
    "col_row = np.load(f\"/home/zluo/output/{netlist_name}.npy\")\n",
    "\n",
    "with open(f'/home/zluo/output/{netlist_name}bTerm.pkl', 'rb') as handle:\n",
    "    dterm = pickle.load(handle)\n",
    "    dterm = dict((v,k) for k,v in dterm.items())\n",
    "    \n",
    "with open(f'/home/zluo/output/{netlist_name}inst.pkl', 'rb') as handle:\n",
    "    dinst = pickle.load(handle)\n",
    "    dinst = dict((v,k) for k,v in dinst.items())\n",
    "\n",
    "with open(f'/home/zluo/output/{netlist_name}all.pkl', 'rb') as handle:\n",
    "    dall = pickle.load(handle)\n",
    "\n",
    "    # dall = {}\n",
    "# dall.update(dterm)\n",
    "# dall.update(dinst)\n",
    "\n",
    "# dtype = {}\n",
    "# for node in dall.keys():\n",
    "#     if node in dterm:\n",
    "#         dtype[node] = \"bTerm\"\n",
    "#     else:\n",
    "#         dtype[node] = \"inst\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fdde8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "netlist_name = \"jpeg_300_off_low_GENUS_o\"\n",
    "col_row = np.load(f\"{netlist_name}.npy\")\n",
    "col = col_row[0]\n",
    "row = col_row[1]\n",
    "edgs = np.array([col, row]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd54860a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the Graph (undirected)\n",
    "edgelist = []\n",
    "for edge in col_row.T:\n",
    "    new_edge = (edge[0], edge[1])\n",
    "    edgelist.append(new_edge)\n",
    "    \n",
    "G = nx.DiGraph(edgelist)\n",
    "nodelist = [node for node in G.nodes]\n",
    "nodelist = sorted(nodelist)\n",
    "adj = nx.adjacency_matrix(G, nodelist=nodelist)\n",
    "p_input = set()\n",
    "p_output = set()\n",
    "o_d = G.out_degree\n",
    "i_d = G.in_degree\n",
    "\n",
    "for node in G:\n",
    "    if o_d[node] == 0 and i_d[node] == 0:\n",
    "        continue\n",
    "\n",
    "    if o_d[node] == 0:\n",
    "        p_output.add(node)\n",
    "\n",
    "    if i_d[node] == 0:\n",
    "        p_input.add(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8c1f8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "all_dist_raw = []\n",
    "edgs_d = [(lst[0], lst[1], 1) for lst in edgs] \n",
    "n = np.max(list(col) + list(row)) + 1\n",
    "graph = Graph(edgs_d, n)\n",
    "for node in p_input: all_dist_raw.append(findLongestDistance(graph, node, n))\n",
    "\n",
    "# building the delay based dictionary\n",
    "delay_dict = all_dist_raw[0]\n",
    "delay_dict = {key: list(delay_dict[key]) for key in delay_dict.keys()}\n",
    "for dist in all_dist_raw[1:]:\n",
    "    for key in dist.keys(): \n",
    "        val = dist[key]\n",
    "        if key in delay_dict.keys():\n",
    "            delay_dict[key] = delay_dict[key] + list(val)\n",
    "        else:\n",
    "            delay_dict[key] = list(val)\n",
    "\n",
    "delay_dict = {key: max(delay_dict[key]) for key in delay_dict.keys()}\n",
    "\n",
    "with open(f'delay_dict_{netlist_name}.pkl', 'wb') as f:\n",
    "    pickle.dump(delay_dict, f)\n",
    "#####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82a8075f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gpickle(G, f\"{netlist_name}.gpickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7a982a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "long = True\n",
    "col = col_row[0]\n",
    "row = col_row[1]\n",
    "edgs = np.array([col, row]).T\n",
    "\n",
    "if long:\n",
    "    #####################################\n",
    "    all_dist_raw = []\n",
    "    edgs_d = [(lst[0], lst[1], 1) for lst in edgs] \n",
    "    n = len(np.unique(row + col))\n",
    "    graph = Graph(edgs_d, n)\n",
    "    for node in p_input: all_dist_raw.append(findLongestDistance(graph, node, n))\n",
    "\n",
    "    # building the delay based dictionary\n",
    "    delay_dict = all_dist_raw[0]\n",
    "    delay_dict = {key: list(delay_dict[key]) for key in delay_dict.keys()}\n",
    "    for dist in all_dist_raw[1:]:\n",
    "        for key in dist.keys(): \n",
    "            val = dist[key]\n",
    "            if key in delay_dict.keys():\n",
    "                delay_dict[key] = delay_dict[key] + list(val)\n",
    "            else:\n",
    "                delay_dict[key] = list(val)\n",
    "\n",
    "    delay_dict = {key: max(delay_dict[key]) for key in delay_dict.keys()}\n",
    "    ##########################################\n",
    "else:\n",
    "    # building the delay based dictionary\n",
    "    s_all_raw = []\n",
    "    for v in p_input:\n",
    "        s_all_raw.append(nx.shortest_path_length(G, v))    \n",
    "\n",
    "    delay_dict = all_raw[0]\n",
    "    delay_dict = {key: [delay_dict[key]] for key in delay_dict.keys()}\n",
    "    for dist in s_all_raw[1:]:\n",
    "        for key in dist.keys(): \n",
    "            val = dist[key]\n",
    "            if key in delay_dict.keys():\n",
    "                delay_dict[key] = delay_dict[key] + [val]\n",
    "            else:\n",
    "                delay_dict[key] = [val]\n",
    "\n",
    "    delay_dict = {key: min(delay_dict[key]) for key in delay_dict.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a83ad53",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('delay_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(delay_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c774ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.set_node_attributes(G, dall, \"inst_name\")\n",
    "nx.set_node_attributes(G, dtype, \"type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd53cccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_d_dict = {}\n",
    "for node in nodelist:\n",
    "    try:\n",
    "        inst = G.nodes[node]['inst_name']\n",
    "        idx_d_dict[node] = float(new_d_dict[inst])\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c10cc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_inst = set()\n",
    "for node in idx_d_dict.keys():\n",
    "    delay = idx_d_dict[node]\n",
    "    if np.isclose(delay, 0):\n",
    "        s_inst.add(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8fe509",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_delay = {node:delay_dict[node] for node in nodelist}\n",
    "\n",
    "d_lst = []\n",
    "for delay in range(max(sub_delay.values()) + 1):\n",
    "    delay_level_lst = []\n",
    "    for node in sub_delay.keys():\n",
    "        if sub_delay[node] == delay:\n",
    "            delay_level_lst.append(node)\n",
    "    \n",
    "    if len(delay_level_lst) == 0:\n",
    "        continue\n",
    "    d_lst.append(delay_level_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ab451a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sub_delay.pkl', 'wb') as f:\n",
    "    pickle.dump(sub_delay, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8561658b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sub_delay.pkl', 'rb') as f:\n",
    "    sub_delay = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee52db19",
   "metadata": {},
   "outputs": [],
   "source": [
    "mid = np.max([len(lst) for lst in d_lst])/2\n",
    "pos = {}\n",
    "for delay in range(len(d_lst)):\n",
    "    lst = d_lst[delay]\n",
    "    for in_pos in range(len(lst)):\n",
    "        node = lst[in_pos]\n",
    "        pos[node] = ((mid - len(lst)) + in_pos*2, (len(d_lst) - delay)*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218eb676",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {}\n",
    "for lst in d_lst:\n",
    "    for node in lst:\n",
    "        if node in s_inst:\n",
    "            val = str(delay_dict[node]) + \" \" + str(node)\n",
    "            labels[node] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c600387f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(10,50), dpi=100) \n",
    "nx.draw(sub_G, node_size=20, pos=pos, width=0.3, arrowsize=5, node_color=color, labels=labels, font_size=8)\n",
    "f.savefig(\"graph.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9594c6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodelist = []\n",
    "for lst in d_lst:\n",
    "    for node in lst:\n",
    "        n_nodelist.append(node)\n",
    "    \n",
    "nodelist = n_nodelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6913bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"nodelist.npy\", nodelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4489e804",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_d_lst = []\n",
    "for idx1 in range(len(nodelist)):\n",
    "    s_n = nodelist[idx1]\n",
    "    dgms1 = np.load(f\"dgms/pd_{s_n}.npy\", allow_pickle=True).tolist()\n",
    "    dgm1 = dgms1[0] + dgms1[1] + dgms1[2]\n",
    "    dgm1 = np.array([tp[-1] for tp in dgm1])\n",
    "    inner_lst = []\n",
    "    for idx2 in range(idx1, len(nodelist)):\n",
    "        dgms2 = np.load(f\"dgms/pd_{nodelist[idx2]}.npy\", allow_pickle=True).tolist()\n",
    "        dgm2 = dgms2[0] + dgms2[1] + dgms2[2]\n",
    "        dgm2 = np.array([tp[-1] for tp in dgm2])\n",
    "        inner_lst.append(persim.sliced_wasserstein(dgm1, dgm2, M=50))\n",
    "    \n",
    "    w_d_lst.append(inner_lst)\n",
    "    if idx1//500 > 0 and idx1%500 == 0:\n",
    "        print(idx1)\n",
    "        np.save(\"w_d_lst.npy\", w_d_lst)\n",
    "        \n",
    "np.save(\"w_d_lst.npy\", w_d_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb22278f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_s = []\n",
    "for node in nodelist:\n",
    "    if node in s_inst:\n",
    "        sub_s.append(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c34e323",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_d_lst = np.load(\"w_d_lst_1_nets.npy\", allow_pickle=True)\n",
    "N = len(w_d_lst)\n",
    "b_symm = np.random.random(size=(N,N))\n",
    "for idx in range(len(w_d_lst)):\n",
    "    lst = w_d_lst[idx]\n",
    "        val = lst[in_idx]\n",
    "        b_symm[idx][(len(w_d_lst)-len(lst))+in_idx] = val\n",
    "        b_symm[(len(w_d_lst)-len(lst))+in_idx][idx] = val\n",
    "np.save(\"b_symm_0_nets.npy\", b_symm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7586a99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_symm = np.load(\"b_symm_0_nets.npy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
